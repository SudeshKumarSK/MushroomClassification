{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "## EE559 Final Project ===> Mushroom Classification.\n",
    "## Created by Sudesh Kumar Santhosh Kumar and Thejesh Chandar Rao.\n",
    "## Date: 6th May, 2023\n",
    "## Tested in Python 3.10.9 using conda environment version 22.9.0.\n",
    "##############################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project -> Classification of Mushrooms (EE - 559)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Data Cleansing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset v1 from Encoding Directory which has the Encoded Features. (Every feature is numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./dataset/Encoded/mushroom_train_v1.csv\")\n",
    "print(\"Train Data Encoded-> 1: \")\n",
    "train_data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Input Features and class labels from the dataset. Also Encoding the class labels from \"p\" -> 1 and \"e\" -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('class', axis=1)  # Select all the features except labels,\n",
    "y_train = train_data['class']  # Select only the 'class' column.\n",
    "\n",
    "class_map = {\"e\" : 0, \"p\" : 1}\n",
    "y_train_enc = y_train.map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeatures = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "numericalFeatures = [col for col in X_train.columns if X_train[col].dtype == \"float64\"]\n",
    "\n",
    "classes, class_index, class_count = np.unique(y_train, return_index=True, return_counts=True, axis=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Dataset for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Categorical Features: {categoricalFeatures}\")\n",
    "print(f\"Numerical Features: {numericalFeatures}\")\n",
    "print(f\"Total number of Categorical Features: {len(categoricalFeatures)}\")\n",
    "print(f\"Total number of Numerical Features: {len(numericalFeatures)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Cross-Correlation co-efficent between Features & Y_train and plotting the absolute values of pearson's co-efficent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlations between all features and output label\n",
    "correlations = X_train.corrwith(y_train_enc, method='pearson')\n",
    "\n",
    "# Sort the correlations by absolute value\n",
    "correlations_sorted = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "# Create the bar chart using seaborn\n",
    "plt.figure(figsize=(10, 20))\n",
    "sns.barplot(x=correlations_sorted.values, y=correlations_sorted.index, palette='viridis')\n",
    "plt.xlabel('Pearson Correlation Co-efficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Correlation Co-efficients with Output Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering the top features which have a threhold value of Pearson's co-efficient > threshold from a list thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.100, 0.125, 0.150, 0.175, 0.200]\n",
    "\n",
    "for (i, threshold) in enumerate(thresholds):\n",
    "    # Select the features with correlation coefficient greater than the threshold\n",
    "    top_features = correlations_sorted[correlations_sorted > threshold].index.tolist()\n",
    "\n",
    "    X_train_top_pearson = X_train[top_features]\n",
    "\n",
    "    train_data_top_pearson = pd.concat([X_train_top_pearson, y_train_enc], axis=1)\n",
    "\n",
    "    print(f\"Pearson Co-efficient Technique version: {i+1} & Threshold value: {threshold}\")\n",
    "    print(f\"Shape of Training Data after performing Feature Selection using Correlation: {train_data_top_pearson.shape}\")\n",
    "    print(f\"Number of Features before performing Feature Selection using Correlation: {train_data.shape[1] - 1} features\")\n",
    "    print(f\"Number of Features after performing Feature Selection using Correlation: {train_data_top_pearson.shape[1] - 1} features\")\n",
    "    print()\n",
    "\n",
    "    ### Converting the data-frame with 37 features to csv file to perform Feature Transformation. (Saving this as v1)\n",
    "    train_data_top_pearson.to_csv(f\"./dataset/FeatureSelected/Pearson/mushroom_train_v{i+1}.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the D' number of features from the D = 147 features by training a simple linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the performance of each feature\n",
    "feature_performances_linear = []\n",
    "\n",
    "# Loop over all features in X_train\n",
    "for feature in X_train.columns:\n",
    "    \n",
    "    # Create a new instance of the logistic regression model\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    \n",
    "    # Fit the model using the current feature only\n",
    "    model.fit(X_train[[feature]], y_train)\n",
    "    \n",
    "    # Make predictions using the current feature only\n",
    "    y_pred = model.predict(X_train[[feature]])\n",
    "    \n",
    "    # Calculate the accuracy of the model using the current feature only\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    \n",
    "    # Store the performance of the current feature\n",
    "    feature_performances_linear.append((feature, accuracy))\n",
    "\n",
    "# Sort the features by their performance (accuracy)\n",
    "feature_performances_linear = sorted(feature_performances_linear, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_primes_linear = [12, 8, 4, 2]\n",
    "\n",
    "for i, d_prime in enumerate(d_primes_linear):\n",
    "    top_features_linear = [x[0] for x in feature_performances_linear[:d_prime]]\n",
    "\n",
    "    X_train_top_linear = X_train[top_features_linear]\n",
    "\n",
    "    train_data_top_linear = pd.concat([X_train_top_linear, y_train_enc], axis=1)\n",
    "\n",
    "    print(f\"Linear Model Technique version: {i+1} & d_prime: {d_prime}\")\n",
    "    print(f\"Shape of Training Data after performing Feature Selection using Linear Model: {train_data_top_linear.shape}\")\n",
    "    print(f\"Number of Features before performing Feature Selection using Linear Model: {train_data.shape[1] - 1} features\")\n",
    "    print(f\"Number of Features after performing Feature Selection using Linear Model: {train_data_top_linear.shape[1] - 1} features\")\n",
    "    print()\n",
    "\n",
    "    ### Converting the data-frame with 37 features to csv file to perform Feature Transformation. (Saving this as v1)\n",
    "    train_data_top_linear.to_csv(f\"./dataset/FeatureSelected/LinearRegression/mushroom_train_v{i+1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
